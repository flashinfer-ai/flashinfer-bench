{
  "name": "gemini-2.5-pro_cuda_4bc599",
  "definition": "gemm_n6144_k4096",
  "author": "gemini-2.5-pro",
  "spec": {
    "language": "cuda",
    "target_hardware": [
      "B200"
    ],
    "entry_point": "main.cpp::run",
    "dependencies": []
  },
  "sources": [
    {
      "path": "kernel.h",
      "content": "#ifndef GEMM_N6144_K4096_KERNEL_H\n#define GEMM_N6144_K4096_KERNEL_H\n\n#include <cuda_fp16.h>\n#include <cuda_runtime.h>\n#include <cublas_v2.h>\n\n/**\n * @brief Launches a GEMM CUDA kernel for C = A * B.T using cuBLAS.\n *\n * This function is a host-side wrapper that calls the highly optimized cuBLAS\n * library to perform the GEMM operation. It is configured to use Tensor Cores\n * for B200-class GPUs and is tailored for the problem dimensions N=6144, K=4096.\n *\n * @param handle A valid cuBLAS library handle.\n * @param M The variable dimension of matrix A and C.\n * @param A Pointer to the input matrix A in device memory, with dimensions [M, K].\n * @param B Pointer to the input matrix B in device memory, with dimensions [N, K].\n * @param C Pointer to the output matrix C in device memory, with dimensions [M, N].\n * @param stream The CUDA stream on which to enqueue the cuBLAS operation.\n */\nvoid gemm_n6144_k4096_launcher(\n    cublasHandle_t handle,\n    int M,\n    const __half* A,\n    const __half* B,\n    __half* C,\n    cudaStream_t stream);\n\n#endif // GEMM_N6144_K4096_KERNEL_H"
    },
    {
      "path": "kernel.cu",
      "content": "#include \"kernel.h\"\n#include <stdexcept>\n#include <string>\n\n// cuBLAS error checking macro\n#define CUBLAS_CHECK(status)                                                   \\\n  do {                                                                         \\\n    cublasStatus_t err = status;                                               \\\n    if (err != CUBLAS_STATUS_SUCCESS) {                                        \\\n      throw std::runtime_error(                                                \\\n          \"cuBLAS error in \" + std::string(__FILE__) + \":\" + std::to_string(__LINE__) + \\\n          \": \" + std::to_string(err));                                         \\\n    }                                                                          \\\n  } while (0)\n\nvoid gemm_n6144_k4096_launcher(\n    cublasHandle_t handle,\n    int M,\n    const __half* A,\n    const __half* B,\n    __half* C,\n    cudaStream_t stream) {\n\n    // Associate the cuBLAS handle with the provided CUDA stream\n    CUBLAS_CHECK(cublasSetStream(handle, stream));\n\n    // Define fixed dimensions from specification\n    constexpr int N = 6144;\n    constexpr int K = 4096;\n\n    // Define scaling factors for C = alpha * op(A) * op(B) + beta * C\n    const float alpha = 1.0f;\n    const float beta = 0.0f;\n\n    // --- Corrected cuBLAS logic for Row-Major GEMM ---\n    // The target operation is C_rm[M, N] = A_rm[M, K] * B_rm[N, K]^T.\n    // cuBLAS expects column-major matrices. The standard formula to map a\n    // row-major GEMM `C_rm = opA(A_rm) @ opB(B_rm)` to a column-major library is\n    // to compute `C_cm = opB(B_rm) @ opA(A_rm)`.\n    // In our case, opA is identity and opB is transpose.\n    // C_rm = A_rm @ B_rm^T  =>  C_cm = B_rm @ A_rm^T\n    //\n    // How cuBLAS interprets our row-major pointers:\n    // - `B_rm[N, K]` is treated as a column-major matrix `P_cm[K, N]`.\n    // - `A_rm[M, K]` is treated as a column-major matrix `Q_cm[K, M]`.\n    //\n    // The operation C_cm = B_rm @ A_rm^T becomes: C_cm = P_cm^T @ Q_cm\n    //\n    // Mapping to cublasGemmEx parameters:\n    // - First matrix (cublas A) is `P_cm` (our B), op = CUBLAS_OP_T\n    // - Second matrix (cublas B) is `Q_cm` (our A), op = CUBLAS_OP_N\n    //\n    // Dimensions for the operation `op(P) @ op(Q)`:\n    // op(P) = P_cm^T has dims [N, K]\n    // op(Q) = Q_cm   has dims [K, M]\n    // Result C_cm has dims [N, M] (memory-equivalent to C_rm[M, N])\n    //\n    // cublasGemmEx parameters (m, n, k):\n    // m: rows of op(P) and C -> N\n    // n: cols of op(Q) and C -> M\n    // k: cols of op(P) / rows of op(Q) -> K\n    //\n    // This setup satisfies the cuBLAS leading dimension constraints.\n    CUBLAS_CHECK(cublasGemmEx(\n        handle,\n        CUBLAS_OP_T,       // Transpose for B (our P_cm)\n        CUBLAS_OP_N,       // Transpose for A (our Q_cm)\n        N,                 // Rows of op(B^T) and C_cm     (m)\n        M,                 // Columns of op(A) and C_cm    (n)\n        K,                 // Cols of op(B^T), rows of op(A) (k)\n        &alpha,            // Host pointer to alpha\n        B,                 // Pointer to matrix B (P_cm)\n        CUDA_R_16F,        // Dtype of B\n        K,                 // Leading dimension of B_rm\n        A,                 // Pointer to matrix A (Q_cm)\n        CUDA_R_16F,        // Dtype of A\n        K,                 // Leading dimension of A_rm\n        &beta,             // Host pointer to beta\n        C,                 // Pointer to matrix C\n        CUDA_R_16F,        // Dtype of C\n        N,                 // Leading dimension of C_rm\n        CUDA_R_32F,        // Use FP32 for accumulation precision\n        CUBLAS_GEMM_DEFAULT_TENSOR_OP // Use Tensor Cores\n    ));\n}"
    },
    {
      "path": "main.cpp",
      "content": "#include <torch/extension.h>\n#include <c10/cuda/CUDAStream.h>\n#include <cublas_v2.h>\n#include <memory>\n#include \"kernel.h\"\n\n// Helper macros for PyTorch tensor validation\n#define CHECK_CUDA(x) TORCH_CHECK(x.is_cuda(), #x \" must be a CUDA tensor\")\n#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n#define CHECK_DTYPE_FP16(x) TORCH_CHECK(x.scalar_type() == torch::kFloat16, #x \" must be a Float16 tensor\")\n#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x); CHECK_DTYPE_FP16(x)\n\n// RAII wrapper for cublasHandle_t to ensure it's always destroyed.\nstruct CublasHandle {\n    cublasHandle_t handle;\n    CublasHandle() {\n        TORCH_CHECK(cublasCreate(&handle) == CUBLAS_STATUS_SUCCESS, \"cuBLAS handle creation failed\");\n    }\n    ~CublasHandle() {\n        cublasDestroy(handle);\n    }\n    // Allow the struct to be passed directly to functions expecting a handle\n    operator cublasHandle_t() const { return handle; }\n};\n\n/**\n * @brief Python-bindable function to execute the GEMM operation.\n *\n * This function takes two PyTorch tensors, A and B, validates them,\n * and calls the custom CUDA/cuBLAS kernel to compute C = A * B.T.\n *\n * @param A A torch::Tensor with shape [M, 4096] and dtype float16, on a CUDA device.\n * @param B A torch::Tensor with shape [6144, 4096] and dtype float16, on a CUDA device.\n * @return A torch::Tensor with shape [M, 6144] and dtype float16, on the same CUDA device.\n */\ntorch::Tensor run(torch::Tensor A, torch::Tensor B) {\n    // ---- Input Validation ----\n    CHECK_INPUT(A);\n    CHECK_INPUT(B);\n\n    TORCH_CHECK(A.dim() == 2, \"Input tensor A must be 2-dimensional\");\n    TORCH_CHECK(B.dim() == 2, \"Input tensor B must be 2-dimensional\");\n\n    // Check against fixed dimensions from the specification\n    constexpr int N_dim = 6144;\n    constexpr int K_dim = 4096;\n\n    TORCH_CHECK(B.size(0) == N_dim, \"B.shape[0] must be \", N_dim);\n    TORCH_CHECK(A.size(1) == K_dim, \"A.shape[1] must be \", K_dim);\n    TORCH_CHECK(B.size(1) == K_dim, \"B.shape[1] must be \", K_dim);\n\n    const int M_dim = A.size(0);\n\n    // ---- Output Tensor Preparation ----\n    auto C = torch::empty({M_dim, N_dim}, A.options());\n\n    // ---- Kernel Execution ----\n    try {\n        // Create a cuBLAS handle (RAII ensures cleanup)\n        static thread_local CublasHandle handle;\n\n        // Get the current CUDA stream from PyTorch\n        cudaStream_t stream = at::cuda::getCurrentCUDAStream();\n\n        // Get raw data pointers from PyTorch tensors\n        const __half* ptr_A = reinterpret_cast<const __half*>(A.data_ptr<at::Half>());\n        const __half* ptr_B = reinterpret_cast<const __half*>(B.data_ptr<at::Half>());\n        __half* ptr_C = reinterpret_cast<__half*>(C.data_ptr<at::Half>());\n        \n        // Launch the custom CUDA kernel\n        gemm_n6144_k4096_launcher(handle, M_dim, ptr_A, ptr_B, ptr_C, stream);\n\n    } catch (const std::exception& e) {\n        // Propagate exceptions from the CUDA code to PyTorch\n        TORCH_CHECK(false, \"GEMM kernel execution failed: \", e.what());\n    }\n\n    // Check for any asynchronous CUDA errors from the kernel launch.\n    // Note: cuBLAS calls are also asynchronous.\n    cudaError_t err = cudaGetLastError();\n    TORCH_CHECK(err == cudaSuccess, \"CUDA error after kernel launch: \", cudaGetErrorString(err));\n\n    return C;\n}\n\n// ---- Pybind11 Module Definition ----\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"run\", &run, \"GEMM(A[M, 4096], B[6144, 4096].T) implementation using cuBLAS, optimized for B200 GPU\");\n}"
    }
  ],
  "description": "gemini-2.5-pro optimized kernel for gemm_n6144_k4096 (round 3)"
}
