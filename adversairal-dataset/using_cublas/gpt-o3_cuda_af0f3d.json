{
  "name": "gpt-o3_cuda_af0f3d",
  "definition": "gemm_n5120_k2048",
  "author": "gpt-o3",
  "spec": {
    "language": "cuda",
    "target_hardware": [
      "B200"
    ],
    "entry_point": "main.cpp::run",
    "dependencies": []
  },
  "sources": [
    {
      "path": "kernel.h",
      "content": "#ifndef GEMM_N5120_K2048_KERNEL_H_\n#define GEMM_N5120_K2048_KERNEL_H_\n\n#include <cuda_fp16.h>\n#include <cuda_runtime.h>\n\n/*  Constants that define the fixed-size axes of the operation  */\nconstexpr int GEMM_N = 5120;   // fixed N  axis\nconstexpr int GEMM_K = 2048;   // fixed K  axis\n\n/*  Helper macro for CUDA error checking  */\n#define CUDA_CHECK(call)                                              \\\n    do {                                                              \\\n        cudaError_t _e = (call);                                      \\\n        if (_e != cudaSuccess) {                                      \\\n            fprintf(stderr,                                           \\\n                    \"CUDA error %s:%d  \\\"%s\\\"\\n\",                     \\\n                    __FILE__, __LINE__, cudaGetErrorString(_e));      \\\n            exit(EXIT_FAILURE);                                       \\\n        }                                                             \\\n    } while (0)\n\n/*  Helper macro for cuBLAS/cuBLASLt error checking  */\n#define CUBLAS_CHECK(call)                                            \\\n    do {                                                              \\\n        cublasStatus_t _s = (call);                                   \\\n        if (_s != CUBLAS_STATUS_SUCCESS) {                            \\\n            fprintf(stderr,                                           \\\n                    \"cuBLAS error %s:%d  code %d\\n\",                  \\\n                    __FILE__, __LINE__, static_cast<int>(_s));        \\\n            exit(EXIT_FAILURE);                                       \\\n        }                                                             \\\n    } while (0)\n\n/*  Forward declaration of the high-performance GEMM implementation.\n    A : pointer to row-major [M , 2048] (__half)\n    B : pointer to row-major [5120 , 2048] (__half)\n    C : pointer to row-major [M , 5120] (__half)   (output)\n    M : runtime-variable length of the free axis\n*/\nvoid gemm_n5120_k2048(const __half* A,\n                      const __half* B,\n                      __half*       C,\n                      int           M,\n                      cudaStream_t  stream = nullptr);\n\n#endif  // GEMM_N5120_K2048_KERNEL_H_"
    },
    {
      "path": "kernel.cu",
      "content": "#include \"kernel.h\"\n\n#include <cublasLt.h>\n#include <cstdio>\n\n/* -------------------------------------------------------------------------- */\n/*  Optional device code: a trivially empty kernel keeps NVCC happy when      */\n/*  the compilation unit otherwise only contains host code.                   */\n/* -------------------------------------------------------------------------- */\n__global__ void _gemm_placeholder_kernel() { /* no-op */ }\n\n/* -------------------------------------------------------------------------- */\n/*  High-performance GEMM based on cuBLASLt, tuned for B200 (Blackwell) GPUs. */\n/*  Row-major tensors and explicit half-precision storage with fp32 compute   */\n/*  ensure both speed (tensor cores) and numerical robustness.                */\n/* -------------------------------------------------------------------------- */\nvoid gemm_n5120_k2048(const __half* A,\n                      const __half* B,\n                      __half*       C,\n                      int           M,\n                      cudaStream_t  stream) {\n    /*  Lazily initialise a single cuBLASLt handle that is re-used for all\n        subsequent calls.  */\n    static cublasLtHandle_t ltHandle = nullptr;\n    if (ltHandle == nullptr) {\n        CUBLAS_CHECK(cublasLtCreate(&ltHandle));\n    }\n\n    /* ------------------------------------------------------------------ */\n    /*  Build the matmul / layout descriptors for the fixed-shape GEMM.   */\n    /* ------------------------------------------------------------------ */\n    const int N = GEMM_N;\n    const int K = GEMM_K;\n\n    cublasOperation_t opA = CUBLAS_OP_N;  // A : (M , K)\n    cublasOperation_t opB = CUBLAS_OP_T;  // B : (N , K)  -> (K , N)\n\n    const cudaDataType_t  dataType   = CUDA_R_16F;  // storage\n    const cublasComputeType_t computeType = CUBLAS_COMPUTE_32F;  // accumulate fp32\n    const float alpha = 1.0f, beta = 0.0f;\n\n    /*  Matmul descriptor (compute + scale types)  */\n    cublasLtMatmulDesc_t opDesc;\n    CUBLAS_CHECK(cublasLtMatmulDescCreate(&opDesc, computeType, CUDA_R_32F));\n    CUBLAS_CHECK(cublasLtMatmulDescSetAttribute(opDesc,\n                                                CUBLASLT_MATMUL_DESC_TRANSA,\n                                                &opA, sizeof(opA)));\n    CUBLAS_CHECK(cublasLtMatmulDescSetAttribute(opDesc,\n                                                CUBLASLT_MATMUL_DESC_TRANSB,\n                                                &opB, sizeof(opB)));\n\n    /*  Row-major layout descriptors for A / B / C  */\n    cublasLtMatrixLayout_t layoutA, layoutB, layoutC;\n    const cublasLtOrder_t rowOrder = CUBLASLT_ORDER_ROW;\n\n    CUBLAS_CHECK(cublasLtMatrixLayoutCreate(&layoutA, dataType, M, K, K));\n    CUBLAS_CHECK(cublasLtMatrixLayoutCreate(&layoutB, dataType, N, K, K));\n    CUBLAS_CHECK(cublasLtMatrixLayoutCreate(&layoutC, dataType, M, N, N));\n\n    CUBLAS_CHECK(cublasLtMatrixLayoutSetAttribute(layoutA,\n                          CUBLASLT_MATRIX_LAYOUT_ORDER, &rowOrder, sizeof(rowOrder)));\n    CUBLAS_CHECK(cublasLtMatrixLayoutSetAttribute(layoutB,\n                          CUBLASLT_MATRIX_LAYOUT_ORDER, &rowOrder, sizeof(rowOrder)));\n    CUBLAS_CHECK(cublasLtMatrixLayoutSetAttribute(layoutC,\n                          CUBLASLT_MATRIX_LAYOUT_ORDER, &rowOrder, sizeof(rowOrder)));\n\n    /* -------------------------------------------------------------- */\n    /*  Heuristic search for a fast algorithm within workspace limit. */\n    /* -------------------------------------------------------------- */\n    constexpr size_t workspaceBytes = 1 << 22;  // 4 MiB\n    static void* workspace = nullptr;\n    if (workspace == nullptr) {\n        CUDA_CHECK(cudaMalloc(&workspace, workspaceBytes));\n    }\n\n    cublasLtMatmulPreference_t preference;\n    CUBLAS_CHECK(cublasLtMatmulPreferenceCreate(&preference));\n    CUBLAS_CHECK(cublasLtMatmulPreferenceSetAttribute(\n        preference,\n        CUBLASLT_MATMUL_PREF_MAX_WORKSPACE_BYTES,\n        &workspaceBytes,\n        sizeof(workspaceBytes)));\n\n    cublasLtMatmulHeuristicResult_t heuristic;\n    int returnedResults = 0;\n    CUBLAS_CHECK(cublasLtMatmulAlgoGetHeuristic(\n        ltHandle, opDesc,\n        layoutA, layoutB, layoutC, layoutC,\n        preference, 1,\n        &heuristic, &returnedResults));\n\n    if (returnedResults == 0) {\n        fprintf(stderr, \"gemm_n5120_k2048: No suitable algorithm found.\\n\");\n        exit(EXIT_FAILURE);\n    }\n\n    /* -------------------------  Launch  --------------------------- */\n    CUBLAS_CHECK(cublasLtMatmul(\n        ltHandle,\n        opDesc,\n        &alpha,\n        A, layoutA,\n        B, layoutB,\n        &beta,\n        C, layoutC,\n        C, layoutC,\n        &heuristic.algo,\n        workspace, workspaceBytes,\n        stream));\n\n    /* --------------------  Clean-up descriptors  ------------------ */\n    CUBLAS_CHECK(cublasLtMatmulPreferenceDestroy(preference));\n    CUBLAS_CHECK(cublasLtMatrixLayoutDestroy(layoutA));\n    CUBLAS_CHECK(cublasLtMatrixLayoutDestroy(layoutB));\n    CUBLAS_CHECK(cublasLtMatrixLayoutDestroy(layoutC));\n    CUBLAS_CHECK(cublasLtMatmulDescDestroy(opDesc));\n\n    CUDA_CHECK(cudaGetLastError());\n}"
    },
    {
      "path": "main.cpp",
      "content": "#include \"kernel.h\"\n\n#include <ATen/cuda/CUDAContext.h>\n#include <torch/extension.h>\n#include <vector>\n\n/*  Public entry point exposed to Python.\n    Accepts:\n        A : torch.float16  [M , 2048]   (CUDA)\n        B : torch.float16  [5120 , 2048](CUDA)\n    Returns:\n        C : torch.float16  [M , 5120]   (CUDA)   */\ntorch::Tensor run(torch::Tensor A, torch::Tensor B) {\n    /*  Basic argument checking  */\n    TORCH_CHECK(A.is_cuda() && B.is_cuda(), \"Inputs must reside on the GPU\");\n    TORCH_CHECK(A.scalar_type() == torch::kFloat16 &&\n                B.scalar_type() == torch::kFloat16,\n                \"Inputs must be float16 / half\");\n    TORCH_CHECK(A.dim() == 2 && B.dim() == 2,\n                \"Inputs must be 2-D matrices\");\n    TORCH_CHECK(A.size(1) == GEMM_K,\n                \"A must have shape [M , 2048]\");\n    TORCH_CHECK(B.size(0) == GEMM_N && B.size(1) == GEMM_K,\n                \"B must have shape [5120 , 2048]\");\n\n    const int64_t M = A.size(0);\n\n    /*  Allocate output tensor on the same device  */\n    auto C = torch::empty({M, GEMM_N},\n                          torch::dtype(torch::kFloat16).device(A.device()));\n\n    /*  Extract the current CUDA stream used by PyTorch  */\n    cudaStream_t stream = at::cuda::getCurrentCUDAStream().stream();\n\n    /*  Launch the optimised GEMM  */\n    gemm_n5120_k2048(\n        reinterpret_cast<const __half*>(A.data_ptr<at::Half>()),\n        reinterpret_cast<const __half*>(B.data_ptr<at::Half>()),\n        reinterpret_cast<__half*>(C.data_ptr<at::Half>()),\n        static_cast<int>(M),\n        stream);\n\n    return C;\n}\n\n/*  PyBind11 module declaration  */\nPYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n    m.def(\"run\", &run, \"Optimised GEMM  (B200, fp16)\");\n}"
    }
  ],
  "description": "o3 optimized kernel for gemm_n5120_k2048 (round 1, reasoning effort: high)"
}
